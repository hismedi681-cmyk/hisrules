import streamlit as st
import pandas as pd
import numpy as np
import re
import base64 
from supabase import create_client, Client, ClientOptions
from httpx import Timeout
import httpx 
from sentence_transformers import SentenceTransformer

# --- 1. í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(
    page_title="ë³‘ì› ê·œì • AI ê²€ìƒ‰ê¸°",
    page_icon="ğŸ¥",
    layout="wide",
    initial_sidebar_state="collapsed" # ì‚¬ì´ë“œë°” ê¸°ë³¸ ë‹«í˜
)

# --- 2. Supabase ë° AI ëª¨ë¸ ì—°ê²° ---
@st.cache_resource
def init_connections():
    try:
        url = st.secrets["supabase"]["url"]
        key = st.secrets["supabase"]["anon_key"]
        
        default_timeout = Timeout(10.0, read=10.0)
        supabase_options = ClientOptions(
            httpx_client=httpx.Client(timeout=default_timeout)
        )
        supabase = create_client(url, key, options=supabase_options)
        ai_model = SentenceTransformer('jhgan/ko-sbert-nli')
        return supabase, ai_model
    except Exception as e:
        st.error(f"âŒ [ì˜¤ë¥˜] ì„œë¹„ìŠ¤ ì—°ê²° ì‹¤íŒ¨: {e}")
        return None, None

@st.cache_data(ttl=600)
def load_map_data(_supabase: Client):
    try:
        response = _supabase.table("regulations_map").select(
            "id, ch_name, std_id, std_name, me_id, me_name, pdf_filename, pdf_url"
        ).order("id").execute()
        
        df = pd.DataFrame(response.data)
        if df.empty: 
            st.warning("âš ï¸ 'ì§€ë„' ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. admin_sync.pyë¥¼ ì‹¤í–‰í–ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
            return pd.DataFrame()
        
        def create_sort_key(std_id_str):
            try:
                parts = re.split(r'[.-]', str(std_id_str))
                return tuple(int(p) for p in parts if p.isdigit())
            except ValueError:
                return (0,)
        df['std_sort_key'] = df['std_id'].apply(create_sort_key)
        return df.sort_values(by=['std_sort_key', 'me_id'])
    except Exception as e:
        st.error(f"âŒ [ì˜¤ë¥˜] 'ì§€ë„' ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return pd.DataFrame()

# --- 3. í•µì‹¬ ê¸°ëŠ¥ í•¨ìˆ˜ ---
def run_ai_search(query_text, search_mode, _supabase, _model):
    if not query_text: return [], None
    try:
        query_vector = _model.encode(query_text).tolist()
        if search_mode == "[AI] ì œëª©/ë¶„ë¥˜ ê²€ìƒ‰":
            st.session_state.ai_status = "âœ… 'ì œëª©/ë¶„ë¥˜' ê²€ìƒ‰ ì¤‘..."
            response = _supabase.rpc('match_map', {
                'query_vector': query_vector, 'match_threshold': 0.3, 'match_count': 10
            }).execute()
            return response.data, "map"
        else: 
            st.session_state.ai_status = "âœ… 'ë³¸ë¬¸ ì „ì²´' ê²€ìƒ‰ ì¤‘..."
            response = _supabase.rpc('match_chunks_all', {
                'query_vector': query_vector, 'match_threshold': 0.5, 'match_count': 5
            }).execute()
            return response.data, "chunks"
    except Exception as e:
        st.error(f"âŒ [ì˜¤ë¥˜] AI ê²€ìƒ‰ ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return [], None

# â˜…â˜…â˜… [í•µì‹¬] PDF Base64 ì¸ì½”ë”© í•¨ìˆ˜ (ë‹¤ìš´ë¡œë“œ ê°•í™”) â˜…â˜…â˜…
@st.cache_data(ttl=3600)
def get_pdf_base64(url: str):
    """ PDF URLì„ ë°›ì•„ Base64 ë¬¸ìì—´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤. (ë³´ì•ˆ ìš°íšŒ) """
    try:
        if url.startswith("http://"): url = url.replace("http://", "https://")
        
        # [ì¤‘ìš”] ë¸Œë¼ìš°ì €ì¸ ì²™ í—¤ë”ë¥¼ ì¶”ê°€í•˜ì—¬ ì°¨ë‹¨ ë°©ì§€
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
        }
        
        response = httpx.get(url, headers=headers, timeout=15.0)
        
        if response.status_code == 200:
            return base64.b64encode(response.content).decode('utf-8')
        else:
            st.error(f"âŒ PDF ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: HTTP {response.status_code}")
            return None
    except Exception as e:
        st.error(f"âŒ PDF ë‹¤ìš´ë¡œë“œ ì˜¤ë¥˜: {e}")
        return None

def render_native_pdf(pdf_url: str, page: int = 1):
    """ ë¸Œë¼ìš°ì € ìì²´ PDF ë·°ì–´ë¥¼ ê°•ì œë¡œ í™œì„±í™”í•˜ëŠ” HTML ìƒì„± """
    if not pdf_url:
        st.info("ê·œì •ì„ ì„ íƒí•˜ì„¸ìš”.")
        return

    # [ì•ˆì „ì¥ì¹˜] ì›ë³¸ ë§í¬ ì œê³µ
    st.markdown(f"""
    <a href="{pdf_url}" target="_blank" style="
        display: inline-block;
        background-color: #f0f2f6;
        color: #31333F;
        padding: 6px 12px;
        border-radius: 4px;
        text-decoration: none;
        font-size: 14px;
        margin-bottom: 10px;
        border: 1px solid #d6d6d8;">
        â†—ï¸ ìƒˆ ì°½ì—ì„œ PDF ì›ë³¸ ì—´ê¸° (í™”ë©´ì´ ì•ˆ ë³´ì´ë©´ í´ë¦­)
    </a>
    """, unsafe_allow_html=True)

    with st.spinner("ğŸ“„ PDF ë¬¸ì„œë¥¼ ë¡œë”© ì¤‘ì…ë‹ˆë‹¤..."):
        base64_pdf = get_pdf_base64(pdf_url)
    
    if base64_pdf:
        # data URI ë°©ì‹ìœ¼ë¡œ PDF ë°ì´í„° ì§ì ‘ ì£¼ì…
        pdf_display = f'<iframe src="data:application/pdf;base64,{base64_pdf}#page={page}" width="100%" height="1000px" type="application/pdf" style="border:none;"></iframe>'
        st.markdown(pdf_display, unsafe_allow_html=True)
    else:
        st.warning("âš ï¸ PDF ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ìœ„ì˜ 'ìƒˆ ì°½ì—ì„œ ì—´ê¸°' ë²„íŠ¼ì„ ì‚¬ìš©í•´ì£¼ì„¸ìš”.")

def set_pdf_url(url: str, page: int):
    st.session_state.current_pdf_url = url
    st.session_state.current_pdf_page = page
    st.session_state.view_mode = "preview" 

# --- 4. UI êµ¬ì„± ---

# (ë³´ì•ˆ ì²´í¬)
def check_password():
    if "password" not in st.session_state: return
    if st.session_state["password"] == st.secrets["app_security"]["common_password"]:
        st.session_state["is_authenticated"] = True
        del st.session_state["password"]
    else:
        st.error("ë¹„ë°€ë²ˆí˜¸ ì˜¤ë¥˜")

if "is_authenticated" not in st.session_state: st.session_state.is_authenticated = False
if "view_mode" not in st.session_state: st.session_state.view_mode = "preview"
if "current_pdf_url" not in st.session_state: st.session_state.current_pdf_url = None
if "current_pdf_page" not in st.session_state: st.session_state.current_pdf_page = 1
if "ai_status" not in st.session_state: st.session_state.ai_status = ""

if not st.session_state.is_authenticated:
    st.title("ğŸ¥ ë³‘ì› ê·œì • AI ê²€ìƒ‰ê¸°")
    with st.container(border=True):
        st.text_input("ë¹„ë°€ë²ˆí˜¸", type="password", on_change=check_password, key="password")
    st.stop()

# (ë©”ì¸ ì•±)
supabase, ai_model = init_connections()
if not supabase or not ai_model: st.stop()
map_data = load_map_data(supabase)

st.title("ğŸ¥ ë³‘ì› ê·œì • AI ê²€ìƒ‰ê¸°")

# (ì „ì²´ í™”ë©´ ëª¨ë“œ)
if st.session_state.view_mode == "fullscreen":
    st.button("ğŸ”™ ëª©ë¡ ë³´ê¸°", on_click=lambda: st.session_state.update(view_mode="preview"), width='stretch')
    if st.session_state.current_pdf_url:
        render_native_pdf(st.session_state.current_pdf_url, st.session_state.current_pdf_page)

# (ë¶„í•  í™”ë©´ ëª¨ë“œ)
else:
    col_nav, col_viewer = st.columns([1, 1.5]) 

    with col_nav:
        st.header("íƒìƒ‰")
        search_mode = st.radio("ëª¨ë“œ", ["[AI] ì œëª©/ë¶„ë¥˜ ê²€ìƒ‰", "[AI] ë³¸ë¬¸ ë‚´ìš© ê²€ìƒ‰", "ì œëª© ê²€ìƒ‰ (í‚¤ì›Œë“œ)"])
        search_query = st.text_input("ê²€ìƒ‰ì–´", placeholder="ì˜ˆ: ë‚™ìƒ")
        
        st.subheader("ê·œì • ëª©ë¡")
        
        target_df = map_data
        ai_result_type = None
        
        if search_query:
            if "[AI]" in search_mode:
                with st.spinner(st.session_state.ai_status if st.session_state.ai_status else "AI ê²€ìƒ‰ ì¤‘..."):
                    ai_results, ai_result_type = run_ai_search(search_query, search_mode, supabase, ai_model)
                    
                    if not ai_results:
                        st.info("â„¹ï¸ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                        target_df = pd.DataFrame() # ê²°ê³¼ ì—†ìŒ ì²˜ë¦¬
                    else:
                        if ai_result_type == "map":
                             # ì§€ë„ ê²€ìƒ‰ì´ë©´ ì•„ì½”ë””ì–¸ í•„í„°ë§ì„ ìœ„í•´ target_df ê°±ì‹ 
                             ids = [r['id'] for r in ai_results]
                             target_df = map_data[map_data['id'].isin(ids)]
                        
                        elif ai_result_type == "chunks":
                            # â˜…â˜…â˜… [ê°œì„ ëœ UI] ë³¸ë¬¸ ê²€ìƒ‰ ê²°ê³¼ ì¹´ë“œí˜• ë¦¬ìŠ¤íŠ¸ â˜…â˜…â˜…
                            st.markdown(f"##### ğŸ” '{search_query}' ê´€ë ¨ ë³¸ë¬¸ ê²€ìƒ‰ ê²°ê³¼ ({len(ai_results)}ê±´)")
                            
                            url_map = map_data.drop_duplicates(subset=['pdf_filename'])
                            url_map = pd.Series(url_map.pdf_url.values, index=url_map.pdf_filename).to_dict()

                            for row in ai_results:
                                with st.container(border=True):
                                    # [í—¤ë”] íŒŒì¼ëª… + ì ìˆ˜
                                    c1, c2 = st.columns([4, 1])
                                    c1.markdown(f"**ğŸ“„ {row['pdf_filename']}** (p.{row['page_num']})")
                                    
                                    score = row['similarity']
                                    color = "green" if score >= 0.6 else "orange" if score >= 0.5 else "gray"
                                    c2.markdown(f":{color}[**{score:.0%}**]")
                                    
                                    # [ë³¸ë¬¸ ë‚´ìš© ê°€ê³µ]
                                    raw_text = row['context_chunk']
                                    clean_text = raw_text.replace("[ë³¸ë¬¸]", "").strip()
                                    if clean_text.startswith("...Å¸"): clean_text = clean_text.replace("...Å¸", "...")
                                    
                                    # ê²€ìƒ‰ì–´ í•˜ì´ë¼ì´íŠ¸
                                    if search_query:
                                        clean_text = clean_text.replace(search_query, f":red[**{search_query}**]")
                                    
                                    st.markdown(f"...{clean_text}...")
                                    
                                    # [ë²„íŠ¼]
                                    pdf_url = url_map.get(row['pdf_filename'])
                                    if pdf_url:
                                        st.button(
                                            "ğŸ‘‰ ì´ í˜ì´ì§€ ë°”ë¡œ ë³´ê¸°",
                                            key=f"btn_chunk_{row['id']}",
                                            on_click=set_pdf_url,
                                            args=(pdf_url, row['page_num']),
                                            use_container_width=True
                                        )
                            
                            # ë³¸ë¬¸ ê²€ìƒ‰ ì‹œì—ëŠ” ì•„ì½”ë””ì–¸ì„ ê·¸ë¦¬ì§€ ì•ŠìŒ
                            target_df = pd.DataFrame()

            elif "í‚¤ì›Œë“œ" in search_mode:
                q = search_query.lower()
                target_df = map_data[map_data['ch_name'].str.lower().str.contains(q) | 
                                     map_data['std_name'].str.lower().str.contains(q) |
                                     map_data['me_name'].str.lower().str.contains(q)]
                if target_df.empty: st.info("ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

        # (ì•„ì½”ë””ì–¸ ë Œë”ë§)
        if not target_df.empty:
            # â˜… [ìˆ˜ì •] ê²€ìƒ‰ì–´ê°€ ìˆì„ ë•Œë§Œ(True), ì—†ìœ¼ë©´ ëª¨ë‘ ë‹«ìŒ(False)
            should_expand = True if search_query else False
            
            for ch_name, ch_df in target_df.groupby('ch_name', sort=False):
                with st.expander(f"ğŸ“‚ {ch_name}", expanded=should_expand):
                    for std_name, std_df in ch_df.groupby('std_name', sort=False):
                        std_id = std_df.iloc[0]['std_id']
                        # ë‚´ë¶€ëŠ” í•­ìƒ ë‹«ì•„ë‘  (ë„ˆë¬´ ê¸¸ì–´ì§€ëŠ” ê²ƒ ë°©ì§€) or ê²€ìƒ‰ ì‹œ ì—¼
                        with st.expander(f"ğŸ“™ {std_id} {std_name}", expanded=should_expand):
                            for _, row in std_df.iterrows():
                                st.button(f"ğŸ“„ {row['me_name']}", key=f"btn_{row['id']}", 
                                          on_click=set_pdf_url, args=(row['pdf_url'], 1))

    with col_viewer:
        st.header("ë¯¸ë¦¬ë³´ê¸°")
        if st.session_state.current_pdf_url:
            render_native_pdf(st.session_state.current_pdf_url, st.session_state.current_pdf_page)
        else:
            st.info("ì™¼ìª½ì—ì„œ ê·œì •ì„ ì„ íƒí•˜ì„¸ìš”.")

        st.divider()
        st.button(
            "â†—ï¸ ì „ì²´ í™”ë©´ìœ¼ë¡œ ë³´ê¸°", 
            on_click=lambda: st.session_state.update(view_mode="fullscreen"), 
            width='stretch',
            disabled=(st.session_state.current_pdf_url is None)
        )

# --- ê´€ë¦¬ì íŒ¨ë„ ---
if 'is_admin' not in st.session_state: st.session_state.is_admin = False
st.sidebar.title("ê´€ë¦¬ì íŒ¨ë„")
if st.session_state.is_admin:
    st.sidebar.success("ê´€ë¦¬ì ëª¨ë“œ í™œì„±í™”")
    st.sidebar.markdown("---")
    st.sidebar.dataframe(map_data.head())
else:
    admin_pw = st.sidebar.text_input("ê´€ë¦¬ì ì•”í˜¸:", type="password")
    if admin_pw:
        if admin_pw == st.secrets["app_security"]["admin_password"]:
            st.session_state.is_admin = True
            st.rerun()
        else:
            st.sidebar.error("ì•”í˜¸ê°€ í‹€ë ¸ìŠµë‹ˆë‹¤.")
