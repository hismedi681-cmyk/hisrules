import streamlit as st
import pandas as pd
import numpy as np
import re
from supabase import create_client, Client, ClientOptions
from httpx import Timeout
import httpx 
from sentence_transformers import SentenceTransformer
from streamlit_pdf_viewer import pdf_viewer # â˜… [í•µì‹¬] ì „ìš© ë·°ì–´ ì„í¬íŠ¸

# --- 1. í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(
    page_title="ë³‘ì› ê·œì • AI ê²€ìƒ‰ê¸°",
    page_icon="ğŸ¥",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# --- 2. Supabase ë° AI ëª¨ë¸ ì—°ê²° ---
@st.cache_resource
def init_connections():
    try:
        url = st.secrets["supabase"]["url"]
        key = st.secrets["supabase"]["anon_key"]
        
        default_timeout = Timeout(10.0, read=10.0)
        supabase_options = ClientOptions(
            httpx_client=httpx.Client(timeout=default_timeout)
        )
        supabase = create_client(url, key, options=supabase_options)
        ai_model = SentenceTransformer('jhgan/ko-sbert-nli')
        return supabase, ai_model
    except Exception as e:
        st.error(f"âŒ [ì˜¤ë¥˜] ì„œë¹„ìŠ¤ ì—°ê²° ì‹¤íŒ¨: {e}")
        return None, None

@st.cache_data(ttl=600)
def load_map_data(_supabase: Client):
    try:
        response = _supabase.table("regulations_map").select(
            "id, ch_name, std_id, std_name, me_id, me_name, pdf_filename, pdf_url"
        ).order("id").execute()
        
        df = pd.DataFrame(response.data)
        if df.empty: return pd.DataFrame()
        
        def create_sort_key(std_id_str):
            try:
                parts = re.split(r'[.-]', str(std_id_str))
                return tuple(int(p) for p in parts if p.isdigit())
            except ValueError:
                return (0,)
        df['std_sort_key'] = df['std_id'].apply(create_sort_key)
        return df.sort_values(by=['std_sort_key', 'me_id'])
    except Exception:
        return pd.DataFrame()

# --- 3. í•µì‹¬ ê¸°ëŠ¥ í•¨ìˆ˜ ---
def run_ai_search(query_text, search_mode, _supabase, _model):
    if not query_text: return [], None
    try:
        query_vector = _model.encode(query_text).tolist()
        if search_mode == "[AI] ì œëª©/ë¶„ë¥˜ ê²€ìƒ‰":
            st.session_state.ai_status = "âœ… 'ì œëª©/ë¶„ë¥˜' ê²€ìƒ‰ ì¤‘..."
            response = _supabase.rpc('match_map', {
                'query_vector': query_vector, 'match_threshold': 0.3, 'match_count': 10
            }).execute()
            return response.data, "map"
        else: 
            st.session_state.ai_status = "âœ… 'ë³¸ë¬¸ ì „ì²´' ê²€ìƒ‰ ì¤‘..."
            response = _supabase.rpc('match_chunks_all', {
                'query_vector': query_vector, 'match_threshold': 0.5, 'match_count': 5
            }).execute()
            return response.data, "chunks"
    except Exception:
        return [], None

# â˜…â˜…â˜… [í•µì‹¬ ìˆ˜ì •] PDF ë·°ì–´ í•¨ìˆ˜ (ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš©) â˜…â˜…â˜…
@st.cache_data(ttl=3600) # PDF ë°ì´í„°ë¥¼ ìºì‹±í•˜ì—¬ ì†ë„ í–¥ìƒ
def download_pdf_data(url: str):
    """ Supabase URLì—ì„œ PDF ë°”ì´ë„ˆë¦¬ ë°ì´í„°ë¥¼ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤. """
    try:
        # HTTPS ê°•ì œ ë³€í™˜ (ë³´ì•ˆ ì´ìŠˆ ë°©ì§€)
        if url.startswith("http://"):
            url = url.replace("http://", "https://")
            
        response = httpx.get(url, timeout=10.0)
        if response.status_code == 200:
            return response.content
        return None
    except Exception:
        return None

def render_pdf_viewer(pdf_url: str, page: int = 1):
    """ streamlit-pdf-viewer ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ ì•ˆì „í•˜ê²Œ PDF í‘œì‹œ """
    if not pdf_url:
        st.warning("PDF URLì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    with st.spinner("ğŸ“„ PDF ë¬¸ì„œë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘..."):
        pdf_data = download_pdf_data(pdf_url)
        
    if pdf_data:
        # widthë¥¼ ì„¤ì •í•˜ë©´ ë°˜ì‘í˜•ìœ¼ë¡œ ê½‰ ì°¨ê²Œ ë³´ì…ë‹ˆë‹¤.
        # resolutionì„ ë†’ì´ë©´ ê¸€ìê°€ ì„ ëª…í•´ì§‘ë‹ˆë‹¤.
        pdf_viewer(input=pdf_data, width=700, height=1000, resolution_boost=1.5)
        
        # (ì°¸ê³ ) ì´ ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” ì•„ì§ íŠ¹ì • í˜ì´ì§€ë¡œ ìë™ ìŠ¤í¬ë¡¤í•˜ëŠ” ê¸°ëŠ¥ì´ ë¶ˆì•ˆì •í•˜ì—¬
        # ì „ì²´ ë¬¸ì„œë¥¼ ë³´ì—¬ì£¼ë˜, ì‚¬ìš©ìê°€ ìŠ¤í¬ë¡¤í•˜ë„ë¡ ìœ ë„í•©ë‹ˆë‹¤.
        if page > 1:
            st.caption(f"ğŸ’¡ **{page}í˜ì´ì§€**ë¥¼ ì°¸ê³ í•˜ì„¸ìš”.")
    else:
        st.error("âŒ PDF íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (URL ì˜¤ë¥˜ ë˜ëŠ” ê¶Œí•œ ë¬¸ì œ)")
        st.link_button("â†—ï¸ ìƒˆ ì°½ì—ì„œ ì§ì ‘ ì—´ê¸°", pdf_url)
# â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…

def set_pdf_url(url: str, page: int):
    st.session_state.current_pdf_url = url
    st.session_state.current_pdf_page = page
    st.session_state.view_mode = "preview" 

# --- 4. UI êµ¬ì„± ---

# (ë³´ì•ˆ ì²´í¬)
def check_password():
    if "password" not in st.session_state: return
    if st.session_state["password"] == st.secrets["app_security"]["common_password"]:
        st.session_state["is_authenticated"] = True
        del st.session_state["password"]
    else:
        st.error("ë¹„ë°€ë²ˆí˜¸ ì˜¤ë¥˜")

if "is_authenticated" not in st.session_state: st.session_state.is_authenticated = False
if "view_mode" not in st.session_state: st.session_state.view_mode = "preview"
if "current_pdf_url" not in st.session_state: st.session_state.current_pdf_url = None
if "current_pdf_page" not in st.session_state: st.session_state.current_pdf_page = 1
if "ai_status" not in st.session_state: st.session_state.ai_status = ""

if not st.session_state.is_authenticated:
    st.title("ğŸ¥ ë³‘ì› ê·œì • AI ê²€ìƒ‰ê¸°")
    with st.container(border=True):
        st.text_input("ë¹„ë°€ë²ˆí˜¸", type="password", on_change=check_password, key="password")
    st.stop()

# (ë©”ì¸ ì•±)
supabase, ai_model = init_connections()
if not supabase or not ai_model: st.stop()
map_data = load_map_data(supabase)

st.title("ğŸ¥ ë³‘ì› ê·œì • AI ê²€ìƒ‰ê¸°")

col_nav, col_viewer = st.columns([1, 1.5]) # ë·°ì–´ ê³µê°„ í™•ë³´ë¥¼ ìœ„í•´ ë¹„ìœ¨ ì¡°ì •

with col_nav:
    st.header("íƒìƒ‰")
    search_mode = st.radio("ëª¨ë“œ", ["[AI] ì œëª©/ë¶„ë¥˜ ê²€ìƒ‰", "[AI] ë³¸ë¬¸ ë‚´ìš© ê²€ìƒ‰", "ì œëª© ê²€ìƒ‰ (í‚¤ì›Œë“œ)"])
    search_query = st.text_input("ê²€ìƒ‰ì–´", placeholder="ì˜ˆ: ë‚™ìƒ")
    
    st.subheader("ê·œì • ëª©ë¡")
    
    # (ë¦¬ìŠ¤íŠ¸/ì•„ì½”ë””ì–¸ ë¡œì§ - ê°„ì†Œí™”í•˜ì—¬ ìœ ì§€)
    target_df = map_data
    ai_result_type = None
    
    if search_query:
        if "[AI]" in search_mode:
            with st.spinner("AI ê²€ìƒ‰ ì¤‘..."):
                ai_results, ai_result_type = run_ai_search(search_query, search_mode, supabase, ai_model)
                if ai_results:
                    if ai_result_type == "map":
                         ids = [r['id'] for r in ai_results]
                         target_df = map_data[map_data['id'].isin(ids)]
                    # ë³¸ë¬¸ ê²€ìƒ‰ì€ ë³„ë„ ë¦¬ìŠ¤íŠ¸ë¡œ í‘œì‹œ
                    elif ai_result_type == "chunks":
                        url_map = map_data.drop_duplicates('pdf_filename').set_index('pdf_filename')['pdf_url'].to_dict()
                        for row in ai_results:
                            with st.container(border=True):
                                st.caption(f"ìœ ì‚¬ë„: {row['similarity']:.0%}")
                                chunk = row['context_chunk'].split("[ë³¸ë¬¸]")[-1] if "[ë³¸ë¬¸]" in row['context_chunk'] else row['context_chunk']
                                st.markdown(f"...{chunk[:100]}...")
                                pdf_url = url_map.get(row['pdf_filename'])
                                if pdf_url:
                                    st.button(f"ğŸ“„ {row['pdf_filename']} (p.{row['page_num']})", 
                                              key=f"c_{row['id']}", 
                                              on_click=set_pdf_url, args=(pdf_url, row['page_num']))
                        target_df = pd.DataFrame() # ì•„ì½”ë””ì–¸ ìˆ¨ê¹€

        elif "í‚¤ì›Œë“œ" in search_mode:
            q = search_query.lower()
            target_df = map_data[map_data['me_name'].str.lower().str.contains(q) | map_data['std_name'].str.lower().str.contains(q)]

    # (ì•„ì½”ë””ì–¸ ë Œë”ë§)
    if not target_df.empty:
        for ch, ch_df in target_df.groupby('ch_name', sort=False):
            with st.expander(f"ğŸ“‚ {ch}", expanded=bool(search_query)):
                for std, std_df in ch_df.groupby('std_name', sort=False):
                    std_id = std_df.iloc[0]['std_id']
                    st.caption(f"ğŸ“™ {std_id} {std}")
                    for _, row in std_df.iterrows():
                        st.button(f"ğŸ“„ {row['me_name']}", key=f"btn_{row['id']}", 
                                  on_click=set_pdf_url, args=(row['pdf_url'], 1))

with col_viewer:
    st.header("ë¯¸ë¦¬ë³´ê¸°")
    if st.session_state.current_pdf_url:
        # â˜… ì—¬ê¸°ì„œ ìƒˆë¡œìš´ ë·°ì–´ í•¨ìˆ˜ í˜¸ì¶œ
        render_pdf_viewer(st.session_state.current_pdf_url, st.session_state.current_pdf_page)
    else:
        st.info("ì™¼ìª½ì—ì„œ ê·œì •ì„ ì„ íƒí•˜ì„¸ìš”.")
