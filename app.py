import streamlit as st
import pandas as pd
import numpy as np
import re
import base64 # â˜… [í•µì‹¬] ë°ì´í„°ë¥¼ ì§ì ‘ ì£¼ì…í•˜ê¸° ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
from supabase import create_client, Client, ClientOptions
from httpx import Timeout
import httpx 
from sentence_transformers import SentenceTransformer

# --- 1. í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(
    page_title="ë³‘ì› ê·œì • AI ê²€ìƒ‰ê¸°",
    page_icon="ğŸ¥",
    layout="wide",
    initial_sidebar_state="collapsed" # ê´€ë¦¬ì íŒ¨ë„ ë‹«í˜ ìƒíƒœ ì‹œì‘
)

# --- 2. Supabase ë° AI ëª¨ë¸ ì—°ê²° ---
@st.cache_resource
def init_connections():
    try:
        url = st.secrets["supabase"]["url"]
        key = st.secrets["supabase"]["anon_key"]
        
        default_timeout = Timeout(10.0, read=10.0)
        supabase_options = ClientOptions(
            httpx_client=httpx.Client(timeout=default_timeout)
        )
        supabase = create_client(url, key, options=supabase_options)
        ai_model = SentenceTransformer('jhgan/ko-sbert-nli')
        return supabase, ai_model
    except Exception as e:
        st.error(f"âŒ [ì˜¤ë¥˜] ì„œë¹„ìŠ¤ ì—°ê²° ì‹¤íŒ¨: {e}")
        return None, None

@st.cache_data(ttl=600)
def load_map_data(_supabase: Client):
    try:
        response = _supabase.table("regulations_map").select(
            "id, ch_name, std_id, std_name, me_id, me_name, pdf_filename, pdf_url"
        ).order("id").execute()
        
        df = pd.DataFrame(response.data)
        if df.empty: return pd.DataFrame()
        
        def create_sort_key(std_id_str):
            try:
                parts = re.split(r'[.-]', str(std_id_str))
                return tuple(int(p) for p in parts if p.isdigit())
            except ValueError:
                return (0,)
        df['std_sort_key'] = df['std_id'].apply(create_sort_key)
        return df.sort_values(by=['std_sort_key', 'me_id'])
    except Exception:
        return pd.DataFrame()

# --- 3. í•µì‹¬ ê¸°ëŠ¥ í•¨ìˆ˜ ---
def run_ai_search(query_text, search_mode, _supabase, _model):
    if not query_text: return [], None
    try:
        query_vector = _model.encode(query_text).tolist()
        if search_mode == "[AI] ì œëª©/ë¶„ë¥˜ ê²€ìƒ‰":
            st.session_state.ai_status = "âœ… 'ì œëª©/ë¶„ë¥˜' ê²€ìƒ‰ ì¤‘..."
            response = _supabase.rpc('match_map', {
                'query_vector': query_vector, 'match_threshold': 0.3, 'match_count': 10
            }).execute()
            return response.data, "map"
        else: 
            st.session_state.ai_status = "âœ… 'ë³¸ë¬¸ ì „ì²´' ê²€ìƒ‰ ì¤‘..."
            response = _supabase.rpc('match_chunks_all', {
                'query_vector': query_vector, 'match_threshold': 0.5, 'match_count': 5
            }).execute()
            return response.data, "chunks"
    except Exception:
        return [], None

# â˜…â˜…â˜… [í•µì‹¬ ì „ëµ] Base64 ì¸ì½”ë”©ì„ í†µí•œ ë³´ì•ˆ ìš°íšŒ ë·°ì–´ â˜…â˜…â˜…
@st.cache_data(ttl=3600)
def get_pdf_base64(url: str):
    """ PDF URLì„ ë°›ì•„ Base64 ë¬¸ìì—´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤. (ë³´ì•ˆ ìš°íšŒ) """
    try:
        if url.startswith("http://"): url = url.replace("http://", "https://")
        response = httpx.get(url, timeout=10.0)
        if response.status_code == 200:
            # ë°”ì´ë„ˆë¦¬ ë°ì´í„°ë¥¼ base64 ë¬¸ìì—´ë¡œ ì¸ì½”ë”©
            return base64.b64encode(response.content).decode('utf-8')
    except:
        pass
    return None

def render_native_pdf(pdf_url: str, page: int = 1):
    """ ë¸Œë¼ìš°ì € ìì²´ PDF ë·°ì–´ë¥¼ ê°•ì œë¡œ í™œì„±í™”í•˜ëŠ” HTML ìƒì„± """
    if not pdf_url:
        st.info("ê·œì •ì„ ì„ íƒí•˜ì„¸ìš”.")
        return

    with st.spinner("ğŸ“„ PDF ë·°ì–´ ë¡œë”© ì¤‘..."):
        # 1. ì„œë²„ì—ì„œ PDF ë°ì´í„°ë¥¼ ì§ì ‘ ê°€ì ¸ì˜´ (CORS ìš°íšŒ)
        base64_pdf = get_pdf_base64(pdf_url)
    
    if base64_pdf:
        # 2. ë°ì´í„°ë¥¼ ë¸Œë¼ìš°ì €ì—ê²Œ 'ë‚´ë¶€ ë°ì´í„°'ì¸ ê²ƒì²˜ëŸ¼ ì†ì—¬ì„œ ì£¼ì… (data:application/pdf;base64)
        # '#page=N' íƒœê·¸ë¥¼ ì‚¬ìš©í•˜ì—¬ í•´ë‹¹ í˜ì´ì§€ë¡œ ì´ë™
        pdf_display = f'<iframe src="data:application/pdf;base64,{base64_pdf}#page={page}" width="100%" height="1000px" type="application/pdf" style="border:none;"></iframe>'
        st.markdown(pdf_display, unsafe_allow_html=True)
    else:
        st.error("âŒ PDF ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        st.link_button("â†—ï¸ ìƒˆ ì°½ì—ì„œ ì—´ê¸°", pdf_url)
# â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…

def set_pdf_url(url: str, page: int):
    st.session_state.current_pdf_url = url
    st.session_state.current_pdf_page = page
    st.session_state.view_mode = "preview" 

# --- 4. UI êµ¬ì„± ---

# (ë³´ì•ˆ ì²´í¬)
def check_password():
    if "password" not in st.session_state: return
    if st.session_state["password"] == st.secrets["app_security"]["common_password"]:
        st.session_state["is_authenticated"] = True
        del st.session_state["password"]
    else:
        st.error("ë¹„ë°€ë²ˆí˜¸ ì˜¤ë¥˜")

if "is_authenticated" not in st.session_state: st.session_state.is_authenticated = False
if "view_mode" not in st.session_state: st.session_state.view_mode = "preview"
if "current_pdf_url" not in st.session_state: st.session_state.current_pdf_url = None
if "current_pdf_page" not in st.session_state: st.session_state.current_pdf_page = 1
if "ai_status" not in st.session_state: st.session_state.ai_status = ""

if not st.session_state.is_authenticated:
    st.title("ğŸ¥ ë³‘ì› ê·œì • AI ê²€ìƒ‰ê¸°")
    with st.container(border=True):
        st.text_input("ë¹„ë°€ë²ˆí˜¸", type="password", on_change=check_password, key="password")
    st.stop()

# (ë©”ì¸ ì•±)
supabase, ai_model = init_connections()
if not supabase or not ai_model: st.stop()
map_data = load_map_data(supabase)

st.title("ğŸ¥ ë³‘ì› ê·œì • AI ê²€ìƒ‰ê¸°")

# (ì „ì²´ í™”ë©´ ëª¨ë“œ)
if st.session_state.view_mode == "fullscreen":
    st.button("ğŸ”™ ëª©ë¡ ë³´ê¸°", on_click=lambda: st.session_state.update(view_mode="preview"), width='stretch')
    if st.session_state.current_pdf_url:
        # â˜… ìˆ˜ì •ëœ ë„¤ì´í‹°ë¸Œ ë·°ì–´ í˜¸ì¶œ
        render_native_pdf(st.session_state.current_pdf_url, st.session_state.current_pdf_page)

# (ë¶„í•  í™”ë©´ ëª¨ë“œ)
else:
    col_nav, col_viewer = st.columns([1, 1.5]) 

    with col_nav:
        st.header("íƒìƒ‰")
        search_mode = st.radio("ëª¨ë“œ", ["[AI] ì œëª©/ë¶„ë¥˜ ê²€ìƒ‰", "[AI] ë³¸ë¬¸ ë‚´ìš© ê²€ìƒ‰", "ì œëª© ê²€ìƒ‰ (í‚¤ì›Œë“œ)"])
        search_query = st.text_input("ê²€ìƒ‰ì–´", placeholder="ì˜ˆ: ë‚™ìƒ")
        
        st.subheader("ê·œì • ëª©ë¡")
        
        target_df = map_data
        ai_result_type = None
        
        if search_query:
            if "[AI]" in search_mode:
                with st.spinner("AI ê²€ìƒ‰ ì¤‘..."):
                    ai_results, ai_result_type = run_ai_search(search_query, search_mode, supabase, ai_model)
                    if ai_results:
                        if ai_result_type == "map":
                             ids = [r['id'] for r in ai_results]
                             target_df = map_data[map_data['id'].isin(ids)]
                        elif ai_result_type == "chunks":
                            url_map = map_data.drop_duplicates('pdf_filename').set_index('pdf_filename')['pdf_url'].to_dict()
                            for row in ai_results:
                                with st.container(border=True):
                                    st.caption(f"ìœ ì‚¬ë„: {row['similarity']:.0%}")
                                    chunk = row['context_chunk'].split("[ë³¸ë¬¸]")[-1] if "[ë³¸ë¬¸]" in row['context_chunk'] else row['context_chunk']
                                    st.markdown(f"...{chunk[:100]}...")
                                    pdf_url = url_map.get(row['pdf_filename'])
                                    if pdf_url:
                                        st.button(f"ğŸ“„ {row['pdf_filename']} (p.{row['page_num']})", 
                                                  key=f"c_{row['id']}", 
                                                  on_click=set_pdf_url, args=(pdf_url, row['page_num']))
                            target_df = pd.DataFrame() # ì•„ì½”ë””ì–¸ ìˆ¨ê¹€

            elif "í‚¤ì›Œë“œ" in search_mode:
                q = search_query.lower()
                target_df = map_data[map_data['me_name'].str.lower().str.contains(q) | map_data['std_name'].str.lower().str.contains(q)]

        if not target_df.empty:
            for ch, ch_df in target_df.groupby('ch_name', sort=False):
                with st.expander(f"ğŸ“‚ {ch}", expanded=bool(search_query)):
                    for std, std_df in ch_df.groupby('std_name', sort=False):
                        std_id = std_df.iloc[0]['std_id']
                        st.caption(f"ğŸ“™ {std_id} {std}")
                        for _, row in std_df.iterrows():
                            st.button(f"ğŸ“„ {row['me_name']}", key=f"btn_{row['id']}", 
                                      on_click=set_pdf_url, args=(row['pdf_url'], 1))

    with col_viewer:
        st.header("ë¯¸ë¦¬ë³´ê¸°")
        if st.session_state.current_pdf_url:
            # â˜… ìˆ˜ì •ëœ ë„¤ì´í‹°ë¸Œ ë·°ì–´ í˜¸ì¶œ
            render_native_pdf(st.session_state.current_pdf_url, st.session_state.current_pdf_page)
        else:
            st.info("ì™¼ìª½ì—ì„œ ê·œì •ì„ ì„ íƒí•˜ì„¸ìš”.")

        st.divider()
        st.button(
            "â†—ï¸ ì „ì²´ í™”ë©´ìœ¼ë¡œ ë³´ê¸°", 
            on_click=lambda: st.session_state.update(view_mode="fullscreen"), 
            width='stretch',
            disabled=(st.session_state.current_pdf_url is None)
        )
