import streamlit as st
import pandas as pd
import numpy as np
import re
from supabase import create_client, Client, ClientOptions
from httpx import Timeout
import httpx 
from sentence_transformers import SentenceTransformer

# --- 1. í˜ì´ì§€ ì„¤ì • (íŒŒì¼ ìµœìƒë‹¨) ---
st.set_page_config(
    page_title="ë³‘ì› ê·œì • AI ê²€ìƒ‰ê¸°",
    page_icon="ğŸ¥",
    layout="wide"
)

# --- 2. Supabase ë° AI ëª¨ë¸ ì—°ê²° ---
@st.cache_resource
def init_connections():
    """
    secrets.tomlì—ì„œ ì—°ê²° ì •ë³´ë¥¼ ì½ì–´ Supabase í´ë¼ì´ì–¸íŠ¸ì™€ AI ëª¨ë¸ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
    """
    try:
        url = st.secrets["supabase"]["url"]
        key = st.secrets["supabase"]["anon_key"]
        
        default_timeout = Timeout(10.0, read=10.0)
        supabase_options = ClientOptions(
            httpx_client=httpx.Client(timeout=default_timeout)
        )
        supabase = create_client(url, key, options=supabase_options)
        
        ai_model = SentenceTransformer('jhgan/ko-sbert-nli')
        
        return supabase, ai_model
    except Exception as e:
        st.error(f"âŒ [ì˜¤ë¥˜] ì„œë¹„ìŠ¤ ì—°ê²°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}")
        return None, None

@st.cache_data(ttl=600)
def load_map_data(_supabase: Client):
    """
    [2-Track ìˆ˜ì •] Supabase DBì—ì„œ 'ì§€ë„(map)' ë°ì´í„°ë§Œ ë¡œë“œí•©ë‹ˆë‹¤. (ì•„ì½”ë””ì–¸ UIìš©)
    """
    try:
        # â˜…â˜…â˜… 'match_map'ì´ ë°˜í™˜í•˜ëŠ” ëª¨ë“  ì»¬ëŸ¼ì„ ê°€ì ¸ì˜¤ë„ë¡ ìˆ˜ì • â˜…â˜…â˜…
        response = _supabase.table("regulations_map").select(
            "id, ch_name, std_id, std_name, me_id, me_name, pdf_filename, pdf_url"
        ).order("id").execute()
        # â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…
        
        df = pd.DataFrame(response.data)
        if df.empty:
            st.error("âŒ [ì˜¤ë¥˜] 'ì§€ë„(regulations_map)' ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. admin_sync.pyë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
            return pd.DataFrame()
        
        def create_sort_key(std_id_str):
            try:
                parts = re.split(r'[.-]', str(std_id_str))
                return tuple(int(p) for p in parts if p.isdigit())
            except ValueError:
                return (0,)
                
        df['std_sort_key'] = df['std_id'].apply(create_sort_key)
        df = df.sort_values(by=['std_sort_key', 'me_id']) 
        return df
    except Exception as e:
        st.error(f"âŒ [ì˜¤ë¥˜] 'ì§€ë„' ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return pd.DataFrame()

# --- 3. í•µì‹¬ ê¸°ëŠ¥ í•¨ìˆ˜ ---

def run_ai_search(query_text: str, search_mode: str, _supabase: Client, _model: SentenceTransformer):
    """
    "2-Track" ì „ëµì— ë”°ë¼ ì˜¬ë°”ë¥¸ Supabase í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.
    """
    if not query_text or not _supabase or not _model:
        return [], None
        
    try:
        query_vector = _model.encode(query_text).tolist()
        
        if search_mode == "[AI] ì œëª©/ë¶„ë¥˜ ê²€ìƒ‰":
            st.session_state.ai_status = "âœ… 'ì œëª©/ë¶„ë¥˜'ì—ì„œ AI ê²€ìƒ‰ ì¤‘..."
            response = _supabase.rpc('match_map', {
                'query_vector': query_vector,
                'match_threshold': 0.3, 
                'match_count': 10 # <-- ì•„ì½”ë””ì–¸ êµ¬ì„±ì„ ìœ„í•´ ë” ë§ì´ ê°€ì ¸ì˜µë‹ˆë‹¤.
            }).execute()
            return response.data, "map" 
            
        else: # "[AI] ë³¸ë¬¸ ë‚´ìš© ê²€ìƒ‰"
            st.session_state.ai_status = "âœ… 'ë³¸ë¬¸ ì „ì²´'ì—ì„œ AI ê²€ìƒ‰ ì¤‘..."
            response = _supabase.rpc('match_chunks_all', {
                'query_vector': query_vector,
                'match_threshold': 0.5, 
                'match_count': 5
            }).execute()
            return response.data, "chunks" 

    except Exception as e:
        st.error(f"âŒ [ì˜¤ë¥˜] AI ê²€ìƒ‰ ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        st.exception(e)
        return [], None

def get_pdf_embed_html(pdf_url: str, page: int = 1) -> str:
    """ PDF ì„ë² ë“œ HTML ìƒì„± (í˜ì´ì§€ ì í”„ ê¸°ëŠ¥ í¬í•¨) """
    if not pdf_url:
        return "<p>PDF URLì´ ì—†ìŠµë‹ˆë‹¤.</p>"
    page_to_show = max(1, page)
    final_url = f"{pdf_url}?v={page_to_show}#page={page_to_show}"
    
    return f"""
        <iframe src="{final_url}&navpanes=0&toolbar=0" width="100%" height="1000px" style="border:none;">
            <p>PDFë¥¼ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.</p>
        </iframe>
    """

def set_pdf_url(url: str, page: int):
    """ PDF ë·°ì–´ ìƒíƒœ ë³€ê²½ ì½œë°± """
    st.session_state.current_pdf_url = url
    st.session_state.current_pdf_page = page
    st.session_state.view_mode = "preview" 

# --- 4. Streamlit UI êµ¬ì„± ---

# --- 4-0. ì•± ë³´ì•ˆ (ê³µí†µ ë¹„ë°€ë²ˆí˜¸) ---
def check_password():
    if "password" not in st.session_state or st.session_state.password == "":
        st.session_state.is_authenticated = False
        return
        
    if st.session_state["password"] == st.secrets["app_security"]["common_password"]:
        st.session_state["is_authenticated"] = True
        del st.session_state["password"]
    else:
        st.session_state["is_authenticated"] = False
        st.error("ë¹„ë°€ë²ˆí˜¸ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")

# (ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”)
if "is_authenticated" not in st.session_state:
    st.session_state.is_authenticated = False
if "view_mode" not in st.session_state:
    st.session_state.view_mode = "preview"
if "current_pdf_url" not in st.session_state:
    st.session_state.current_pdf_url = None
if "current_pdf_page" not in st.session_state:
    st.session_state.current_pdf_page = 1
if "ai_status" not in st.session_state:
    st.session_state.ai_status = ""

# --- ë¹„ë°€ë²ˆí˜¸ ì…ë ¥ í™”ë©´ ---
if not st.session_state.is_authenticated:
    st.title("ğŸ¥ ë³‘ì› ê·œì • AI ê²€ìƒ‰ê¸°")
    with st.container(border=True): 
        st.subheader("ë¡œê·¸ì¸")
        st.markdown("ë³‘ì› ê³µí†µ ë¹„ë°€ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
        st.text_input(
            "ë¹„ë°€ë²ˆí˜¸", 
            type="password", 
            on_change=check_password, 
            key="password"
        )
    st.stop() 

# --- ë¹„ë°€ë²ˆí˜¸ í†µê³¼ ì‹œ, ë©”ì¸ ì•± ë¡œë“œ ---

# (ì„œë¹„ìŠ¤ ì—°ê²°)
supabase, ai_model = init_connections()
if not supabase or not ai_model:
    st.stop()

# (ë°ì´í„° ë¡œë“œ)
map_data = load_map_data(supabase) # (ì•„ì½”ë””ì–¸ìš© ì›ë³¸ ë°ì´í„°)
if map_data.empty:
    st.stop()
    
# (í•©ë³¸ PDF URL ë¯¸ë¦¬ ê°€ì ¸ì˜¤ê¸°)
try:
    combined_pdf_url = supabase.storage.from_("regulations").get_public_url("combined_regulations.pdf")
except Exception:
    combined_pdf_url = None

st.title("ğŸ¥ ë³‘ì› ê·œì • AI ê²€ìƒ‰ê¸°")

# --- ì „ì²´ í™”ë©´ ë¡œì§ ---
if st.session_state.view_mode == "fullscreen":
    st.button("ğŸ”™ ëª©ë¡ ë³´ê¸°", on_click=lambda: st.session_state.update(view_mode="preview"), width='stretch')
    
    if st.session_state.current_pdf_url:
        st.markdown(
            get_pdf_embed_html(st.session_state.current_pdf_url, st.session_state.current_pdf_page), 
            unsafe_allow_html=True
        )
    else:
        st.info("í‘œì‹œí•  PDFê°€ ì„ íƒë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 'ëª©ë¡ ë³´ê¸°'ë¡œ ëŒì•„ê°€ì„¸ìš”.")

else:
    # --- [ë¯¸ë¦¬ë³´ê¸° ëª¨ë“œ (ê¸°ë³¸)] ---
    col_nav, col_viewer = st.columns([1, 2]) # 1:2 ë¹„ìœ¨

    # --- ì¢Œì¸¡ ë„¤ë¹„ê²Œì´í„° (col_nav) ---
    with col_nav:
        st.header("íƒìƒ‰")
        
        if combined_pdf_url:
            st.button(
                "ğŸ“‚ [ì „ì²´ í•©ë³¸ ë³´ê¸°]", 
                on_click=set_pdf_url, 
                args=(combined_pdf_url, 1),
                key="btn_combined_pdf",
                width='stretch'
            )
        
        st.divider()
        
        search_mode = st.radio(
            "ê²€ìƒ‰ ëª¨ë“œ", 
            ["[AI] ì œëª©/ë¶„ë¥˜ ê²€ìƒ‰", "[AI] ë³¸ë¬¸ ë‚´ìš© ê²€ìƒ‰", "ì œëª© ê²€ìƒ‰ (í‚¤ì›Œë“œ)"], # <-- 3ê°œ ëª¨ë“œ
            horizontal=True,
            help="""
            - **[AI] ì œëª©/ë¶„ë¥˜ ê²€ìƒ‰:** 'í™˜ì í™•ì¸'ì²˜ëŸ¼ íŠ¹ì • ê¸°ì¤€(ME)ì´ë‚˜ ê·œì •ì§‘ ì œëª©ì„ AIë¡œ ì°¾ìŠµë‹ˆë‹¤. (ì•„ì½”ë””ì–¸ í•„í„°ë§)
            - **[AI] ë³¸ë¬¸ ë‚´ìš© ê²€ìƒ‰:** 'ì†ì”»ê¸° ì ˆì°¨'ì²˜ëŸ¼ ê·œì •ì§‘ ë³¸ë¬¸ì˜ ìƒì„¸ ë‚´ìš©ì„ AIë¡œ ì°¾ìŠµë‹ˆë‹¤. (ë³¸ë¬¸ ì¡°ê° ë¦¬ìŠ¤íŠ¸)
            - **ì œëª© ê²€ìƒ‰ (í‚¤ì›Œë“œ):** 'HIS-1.1'ì²˜ëŸ¼ ì •í™•í•œ í‚¤ì›Œë“œë¡œ ì•„ì½”ë””ì–¸ì„ í•„í„°ë§í•©ë‹ˆë‹¤.
            """
        )
        
        search_query = st.text_input("ğŸ” ê²€ìƒ‰ì–´ ì…ë ¥", placeholder="ì˜ˆ: ë‚™ìƒ í‰ê°€ë„êµ¬, ê°œë°©í˜• ì§ˆë¬¸, HIS-1.1")
        
        st.subheader("ê·œì • ëª©ë¡")
        
        # (1. ê²€ìƒ‰ì–´ê°€ ì—†ì„ ë•Œ - ê¸°ë³¸ ì•„ì½”ë””ì–¸)
        if not search_query:
            st.session_state.ai_status = "" 
            for ch_name, ch_df in map_data.groupby('ch_name', sort=False):
                with st.expander(f"ğŸ“‚ {ch_name}"):
                    for std_name, std_df in ch_df.groupby('std_name', sort=False):
                        std_id = std_df.iloc[0]['std_id']
                        with st.expander(f"ğŸ“™ {std_id} {std_name}"):
                            for _, row in std_df.iterrows():
                                st.button(
                                    f"ğŸ“„ [{row['me_id']}] {row['me_name']}",
                                    key=f"btn_me_{row['id']}", 
                                    on_click=set_pdf_url,
                                    args=(row['pdf_url'], 1) 
                                )
        
        # (2. ê²€ìƒ‰ì–´ê°€ ìˆì„ ë•Œ - í•„í„°ë§ëœ ê²°ê³¼)
        else:
            ai_results = []
            result_type = None
            filtered_df = pd.DataFrame() # ì•„ì½”ë””ì–¸ì„ ê·¸ë¦´ DataFrame

            # --- [AI] ì œëª©/ë¶„ë¥˜ ê²€ìƒ‰ ë¡œì§ (ì•„ì½”ë””ì–¸ í•„í„°ë§) ---
            if search_mode == "[AI] ì œëª©/ë¶„ë¥˜ ê²€ìƒ‰":
                with st.spinner("ğŸ§  AIê°€ 'ì œëª©/ë¶„ë¥˜'(ì„)ë¥¼ ê²€ìƒ‰ ì¤‘ì…ë‹ˆë‹¤..."):
                    st.session_state.ai_status = "..." 
                    ai_results, result_type = run_ai_search(search_query, search_mode, supabase, ai_model)
                
                if not ai_results:
                    st.info(f"â„¹ï¸ 'AI ì œëª©/ë¶„ë¥˜' ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    # â˜…â˜…â˜… [ì˜ë„ ìˆ˜ì •] ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜ â˜…â˜…â˜…
                    filtered_df = pd.DataFrame(ai_results)
                    st.markdown(f"**'{search_query}'(ì™€)ê³¼ ìœ ì‚¬í•œ {len(filtered_df)}ê±´ì˜ í•­ëª©ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.**")

            # --- [AI] ë³¸ë¬¸ ë‚´ìš© ê²€ìƒ‰ ë¡œì§ (ìƒˆ ë¦¬ìŠ¤íŠ¸) ---
            elif search_mode == "[AI] ë³¸ë¬¸ ë‚´ìš© ê²€ìƒ‰":
                with st.spinner("ğŸ§  AIê°€ 'ë³¸ë¬¸ ì „ì²´'(ì„)ë¥¼ ê²€ìƒ‰ ì¤‘ì…ë‹ˆë‹¤..."):
                    st.session_state.ai_status = "..." 
                    ai_results, result_type = run_ai_search(search_query, search_mode, supabase, ai_model)
                
                if not ai_results:
                    st.info(f"â„¹ï¸ 'AI ë³¸ë¬¸ ë‚´ìš©' ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    st.markdown(f"**'{search_query}'(ì™€)ê³¼ ìœ ì‚¬í•œ {len(ai_results)}ê±´ì˜ ë³¸ë¬¸ ì¡°ê°ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.**")
                    
                    # (ë³¸ë¬¸ ê²€ìƒ‰ì€ URL ë§µì´ í•„ìš”í•¨)
                    url_map = map_data.drop_duplicates(subset=['pdf_filename'])
                    url_map = pd.Series(url_map.pdf_url.values, index=url_map.pdf_filename).to_dict()

                    for row in ai_results:
                        st.markdown(f"---")
                        st.info(f"**(p.{row['page_num']}ì—ì„œ ë°œê²¬)** (ìœ ì‚¬ë„: {row['similarity']:.0%})")
                        
                        chunk_content = row['context_chunk']
                        if "[ë³¸ë¬¸] " in chunk_content:
                            chunk_content = chunk_content.split("[ë³¸ë¬¸] ", 1)[-1]
                            
                        highlighted_text = chunk_content.replace(search_query, f"**{search_query}**") 
                        st.markdown(f"> {highlighted_text}...")
                        
                        result_filename = row['pdf_filename']
                        pdf_url_to_open = url_map.get(result_filename) 
                        
                        if pdf_url_to_open:
                            st.button(
                                f"â†—ï¸ ê·œì • ë³´ê¸° ({result_filename}, {row['page_num']}p.ë¡œ ì´ë™)",
                                key=f"ai_btn_chunk_{row['id']}",
                                on_click=set_pdf_url,
                                args=(pdf_url_to_open, row['page_num'])
                            )
                        else:
                            st.error(f"ì˜¤ë¥˜: {result_filename}ì˜ URLì„ 'ì§€ë„(map)'ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

            # --- ì œëª© ê²€ìƒ‰ (í‚¤ì›Œë“œ) ë¡œì§ (ì•„ì½”ë””ì–¸ í•„í„°ë§) ---
            elif search_mode == "ì œëª© ê²€ìƒ‰ (í‚¤ì›Œë“œ)":
                st.session_state.ai_status = "" 
                query = search_query.lower()
                mask = (
                    map_data['ch_name'].str.lower().str.contains(query, na=False) |
                    map_data['std_name'].str.lower().str.contains(query, na=False) |
                    map_data['me_name'].str.lower().str.contains(query, na=False) |
                    map_data['std_id'].str.lower().str.contains(query, na=False) |
                    map_data['me_id'].str.lower().str.contains(query, na=False)
                )
                filtered_df = map_data[mask]
                
                if filtered_df.empty:
                    st.info("â„¹ï¸ 'ì œëª© (í‚¤ì›Œë“œ)' ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    st.markdown(f"**'{search_query}'(ìœ¼)ë¡œ {len(filtered_df)}ê±´ì˜ í•­ëª©ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.**")

            # --- â˜…â˜…â˜… [ì˜ë„ ìˆ˜ì •] ì•„ì½”ë””ì–¸ ë Œë”ë§ ë¡œì§ (ê³µí†µ) â˜…â˜…â˜… ---
            # 'filtered_df'ì— ë‚´ìš©ì´ ìˆìœ¼ë©´ (AI ì œëª© ê²€ìƒ‰ ë˜ëŠ” í‚¤ì›Œë“œ ì œëª© ê²€ìƒ‰ì´ ì„±ê³µí•˜ë©´)
            if not filtered_df.empty:
                # (match_map ê²°ê³¼ëŠ” 'std_sort_key'ê°€ ì—†ìœ¼ë¯€ë¡œ 'ch_name', 'std_name'ìœ¼ë¡œ ê·¸ë£¹í™”)
                # (match_map ê²°ê³¼ì—ëŠ” 'ch_name' ë“±ì´ ì—†ìœ¼ë¯€ë¡œ, ì›ë³¸ map_dataì™€ joiní•´ì•¼ í•¨)
                
                # 'match_map' ê²°ê³¼ (ai_results)ëŠ” 'id'ë§Œ ìˆìŠµë‹ˆë‹¤. 
                # ì´ 'id'ë¥¼ ì‚¬ìš©í•´ ì›ë³¸ 'map_data'ì—ì„œ ì „ì²´ ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
                if result_type == "map":
                     result_ids = filtered_df['id'].tolist()
                     # AIê°€ ì°¾ì€ ID ìˆœì„œëŒ€ë¡œ ì›ë³¸ map_dataì—ì„œ í–‰ì„ í•„í„°ë§í•˜ê³  ì •ë ¬
                     filtered_df = map_data[map_data['id'].isin(result_ids)].set_index('id').loc[result_ids].reset_index()

                # (ê³µí†µ ì•„ì½”ë””ì–¸ ë Œë”ë§)
                for ch_name, ch_df in filtered_df.groupby('ch_name', sort=False):
                    with st.expander(f"ğŸ“‚ {ch_name}", expanded=True):
                        for std_name, std_df in ch_df.groupby('std_name', sort=False):
                            std_id = std_df.iloc[0]['std_id']
                            with st.expander(f"ğŸ“™ {std_id} {std_name}", expanded=True):
                                for _, row in std_df.iterrows():
                                    st.button(
                                        f"ğŸ“„ [{row['me_id']}] {row['me_name']}",
                                        key=f"btn_me_filtered_{row['id']}", 
                                        on_click=set_pdf_url,
                                        args=(row['pdf_url'], 1) 
                                    )

    # --- ìš°ì¸¡ ë·°ì–´ (col_viewer) ---
    with col_viewer:
        st.button(
            "â†—ï¸ ì „ì²´ í™”ë©´ìœ¼ë¡œ ë³´ê¸°", 
            on_click=lambda: st.session_state.update(view_mode="fullscreen"), 
            width='stretch',
            disabled=(st.session_state.current_pdf_url is None)
        )
        st.divider()

        if st.session_state.current_pdf_url:
            st.markdown(
                get_pdf_embed_html(st.session_state.current_pdf_url, st.session_state.current_pdf_page), 
                unsafe_allow_html=True
            )
        else:
            st.info("ì¢Œì¸¡ 'íƒìƒ‰' ë©”ë‰´ì—ì„œ ê·œì •ì„ ì„ íƒí•˜ê±°ë‚˜ 'AI ê²€ìƒ‰'ì„ ì‹¤í–‰í•˜ì„¸ìš”.")

# --- ê´€ë¦¬ì íŒ¨ë„ (st.sidebar) ---
if 'is_admin' not in st.session_state:
    st.session_state.is_admin = False

st.sidebar.title("ê´€ë¦¬ì íŒ¨ë„")
if st.session_state.is_admin:
    st.sidebar.success("ê´€ë¦¬ì ëª¨ë“œ í™œì„±í™”")
    st.sidebar.markdown("---")
    st.sidebar.subheader("ì•± ìƒíƒœ")
    st.sidebar.dataframe(map_data.head())
    st.sidebar.caption(f"ì´ {len(map_data)}ê°œì˜ 'ì§€ë„(ME)' í•­ëª© ë¡œë“œë¨")
else:
    admin_pw = st.sidebar.text_input("ê´€ë¦¬ì ì•”í˜¸:", type="password")
    if admin_pw:
        if admin_pw == st.secrets["app_security"]["admin_password"]:
            st.session_state.is_admin = True
            st.rerun()
        else:
            st.sidebar.error("ì•”í˜¸ê°€ í‹€ë ¸ìŠµë‹ˆë‹¤.")